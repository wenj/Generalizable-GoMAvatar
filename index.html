<!DOCTYPE html>
<html>

<head lang="en">
  <!-- <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> -->

  <!-- <meta http-equiv="x-ua-compatible" content="ie=edge"> -->

  <title>Generalizable GoMAvatar</title>

  <meta name="description" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- mirror: F0%9F%AA%9E&lt -->

  <link rel="stylesheet" type="text/css" href="./files/slick.css">
  <link rel="stylesheet" type="text/css" href="./files/slick-theme.css">
  <link rel="stylesheet" href="./files/bulma.min.css">
  <link rel="stylesheet" href="./files/bulma-slider.min.css">
  <link rel="stylesheet" href="./files/bulma-carousel.min.css">
  <link rel="stylesheet" href="./files/bootstrap.min.css">
  <link rel="stylesheet" href="./files/font-awesome.min.css">
  <link rel="stylesheet" href="./files/codemirror.min.css">
  <link rel="stylesheet" href="./files/app.css">
  <link rel="stylesheet" href="./files/index.css">
  <link rel="stylesheet" href="./files/select.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="resources/glide.core.min.css">
  <link rel="stylesheet" href="resources/glide.theme.min.css">
  <link rel="stylesheet" href="resources/glide-custom.css">
  <script src="resources/handlers.js"></script>
  <script src="./files/jquery.min.js"></script>
  <script src="./files/bootstrap.min.js"></script>
  <script src="./files/codemirror.min.js"></script>
  <script src="./files/clipboard.min.js"></script>
  <script src="./files/video_comparison.js"></script>
  <script src="./files/select.js"></script>
  <script src="./files/bulma-slider.min.js"></script>
  <script src="./files/bulma-carousel.min.js"></script>
  <!-- <script src="./files/app.js"></script> -->
  <script src="./files/index.js"></script>
  <!-- <script src="./files/slick.js"></script> -->

  <script src="resources/glide.min.js"></script>
  <script>
    window.onload = function () {
      new Glide("#dynamic-carousel", {
        type: "carousel",
        perView: 1.68,
        focusAt: "center",
        autoplay: 20000,
        hoverpause: true
      }).mount();
      new Glide("#static-carousel", {
        type: "carousel",
        perView: 1.68,
        focusAt: "center",
        autoplay: 3000,
        hoverpause: true
      }).mount();
      new Glide("#realtime-carousel", {
        type: "carousel",
        perView: 2.05,
        focusAt: "center",
        autoplay: 3000,
        hoverpause: true
      }).mount();
    };
  </script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-RZ6PES7EKD"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-RZ6PES7EKD');
  </script>
</head>

<body>
  <div class="container" id="header" style="text-align: center; margin: auto;">
    <div class="row" id="title-row" style="max-width: 100%; margin: 0 auto; display: inline-block">
      <h2 class="col-md-12 text-center" id="title">
        Generalizable Human Rendering with Learned Iterative Feedback Over Multi-Resolution Gaussians-on-Mesh
      </h2>
      <!-- <h3 class="col-md-12 text-center" id="title">
        CVPR 2024<br>
      </h3> -->
    </div>
  </div>
  <script>
  </script>
  <div class="container" id="main">
    <div class="row">
      <div class="col-sm-10 col-sm-offset-1 text-center">
        <ul class="list-inline">
          <li> <a href="https://wenj.github.io/">Jing Wen</a> </li>
          <li> <a href="https://www.alexander-schwing.de/">Alexander G. Schwing</a> </li>
          <li> <a href="https://shenlong.web.illinois.edu/">Shenlong Wang</a> </li>
        </ul>
        <ul class="list-inline">
          <li> University of Illinois at Urbana-Champaign </li>
          <br />
        </ul>
      </div>
    </div>

    <!-- <div class="row">
      <div class="col-sm-8 col-sm-offset-2 text-center">
        <span class="link-block">
          <a href="https://arxiv.org/abs/2404.07991" class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
              <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas"
                data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"
                data-fa-i2svg="">
                <path fill="currentColor"
                  d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z">
                </path>
              </svg>
            </span>
            <span>Paper</span>
          </a>
        </span>
        <span class="link-block">
          <a href="https://github.com/wenj/GoMAvatar"
            class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
              <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab"
                data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg="">
                <path fill="currentColor"
                  d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z">
                </path>
              </svg>
            </span>
            <span>Code</span>
          </a>
        </span>
      </div>
    </div> -->

    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <h3>
          Abstract
        </h3>
        <div class="text-justify">
          Generalizable reconstruction of an animatable human avatar from sparse inputs and corresponding high-quality rendering conditioned on a given pose faces two main challenges: First, generalizable methods, which are needed for fast reconstruction, avoid scene-specific optimization but instead rely on data priors and inductive biases extracted from training on large data. However, at reconstruction time, information is limited as only a small number of sparse inputs are available. Note, we operate on a small set of images showing a human in possibly different but not multi-view consistent poses. Second, rendering is preferably computationally efficient yet of high resolution. To address both challenges we augment the recently proposed dual shape representation, which combines the benefits of a mesh and Gaussian points, in two ways. To improve reconstruction, we propose an iterative feedback update framework, which successively improves the canonical human shape representation during reconstruction. To achieve computationally efficient yet high-resolution rendering, we study a coupled-multi-resolution Gaussians-on-Mesh representation. We evaluate the proposed approach on the challenging THuman2.0 and AIST++ data. Our approach reconstructs an animatable representation from sparse inputs in less than 1s, renders views with 95.1FPS at 1024x1024, and achieves PSNR/LPIPS*/FID of 24.59/111.26/51.42 on THuman2.0, outperforming the state-of-the-art in rendering quality.
        </div>
        <br>
        <center>
          <img src="./files/figures/teaser.png" class="img-responsive" alt="overview" width="100%"
            style="max-height: 500px;margin:auto;">
        </center>
      </div>
    </div>

    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <h3>
          Reconstruction with iterative feedback
        </h3>
        <div class="text-justify">
          We iteratively update in a feed-forward way the vertices of the low-resolution mesh and the Gaussian parameters attached to the high-resolution mesh. We repeat the update for T steps. Each step t operates on the source images, camera parameters and human poses, as well as the last iteration's results including the canonical representation from the last step and the predicted source images rendered in the last step (the brown arrows).
        </div>
        <br>
        <center>
          <img src="./files/figures/iterative_feedback.png" class="img-responsive" alt="overview" width="100%"
            style="max-height: 500px;margin:auto;">
        </center>
      </div>
    </div>

    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <h3>
          Novel view synthesis
        </h3>
        <div class="text-justify">
            In the following we present 360° freeview rendering and the comparison to GHG [1].
            <br>
            [1] Kwon, Youngjoong, et al. "Generalizable human gaussians for sparse view synthesis." ECCV 2024.
        </div>
        <br>

        <center>
          <ul class="nav nav-pills nav-justified" id="ghg" style="width: 100%">
            <li role="presentation" class="active"><a href="javascript: void(0);"
                onclick="ChangeSceneGHG(0);">0006</a>
            </li>
            <li role="presentation"><a href="javascript: void(0);" onclick="ChangeSceneGHG(1);">0090</a>
            </li>
            <li role="presentation"><a href="javascript: void(0);" onclick="ChangeSceneGHG(2);">0270</a>
            </li>
            <li role="presentation"><a href="javascript: void(0);" onclick="ChangeSceneGHG(3);">0426</a>
            </li>
            <li role="presentation"><a href="javascript: void(0);" onclick="ChangeSceneGHG(4);">0474</a>
            </li>
            <li role="presentation"><a href="javascript: void(0);" onclick="ChangeSceneGHG(5);">0522</a>
            </li>
          </ul>
          <br>

          <div class="container" style="width: 100%">
            <div class="row">
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <video widthcontrols loop autoplay muted id="ghg_gt">
                  <source src="./files/ghg/gt_0090.mp4" type="video/mp4"><br>
                </video>
                <h5>Ground truth</h5>
              </div>
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <video widthcontrols loop autoplay muted id="ghg_ghg">
                  <source src="./files/ghg/ghg_0090.mp4" type="video/mp4"><br>
                </video>
                <h5>GHG</h5>
              </div>
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <video widthcontrols loop autoplay muted id="ghg_ours">
                  <source src="./files/ghg/our_0090.mp4" type="video/mp4"><br>
                </video>
                <h5>Ours</h5>
              </div>
            </div>
          </div>
        </center>
      </div>
    </div>
    <br>

    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <h3>
          Novel pose synthesis
        </h3>
        <div class="text-justify">
            In the following we present novel pose synthesis. We retarget the subject to new pose sequences from the BEDLAM dataset.
        </div>
        <br>

        <center>
          <div class="container" style="width: 100%">
            <div class="row">
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <video widthcontrols loop autoplay muted id="nvs_rgb_hn">
                  <source src="./files/novelpose/scene_0009_name_rp_eve_posed_001.mp4" type="video/mp4"><br>
                </video>
              </div>
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <video widthcontrols loop autoplay muted id="nvs_rgb_mh">
                  <source src="./files/novelpose/scene_0126_name_rp_eve_posed_001.mp4" type="video/mp4"><br>
                </video>
              </div>
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <video widthcontrols loop autoplay muted id="nvs_rgb_ours">
                    <source src="./files/novelpose/scene_0510_name_rp_eve_posed_001.mp4" type="video/mp4"><br>
                </video>
              </div>
            </div>
          </div>
        </center>
      </div>
    </div>
    <br>

    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <h3>
          Cross-domain generalization
        </h3>
        <div class="text-justify">
            In the following we show our method in cross-domain generalization. Our model is trained on THuman2.0. We inference on DNA-Rendering without finetuning. We take three source images as inputs.
        </div>
        <br>

        <center>
          <ul class="nav nav-pills nav-justified" id="crossdomain" style="width: 100%">
            <li role="presentation" class="active"><a href="javascript: void(0);"
                onclick="ChangeSceneCrossDomain(0);">0008_01</a>
            </li>
            <li role="presentation"><a href="javascript: void(0);" onclick="ChangeSceneCrossDomain(1);">0152_01</a>
            </li>
            <li role="presentation"><a href="javascript: void(0);" onclick="ChangeSceneCrossDomain(2);">0310_04</a>
            </li>
          </ul>
          <br>

          <div class="container" style="width: 100%">
            <div class="row">
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <div><img src="./files/crossdomain/scene_0008_01_000000_frame_000020.png" class="img" width="100%" id="crossdomain_ref">
                  <h5>Reference source image</h5>
                </div>
              </div>
              <div class="col-lg-4 col-md-4 col-xs-6 col-sm-4 pull-left" style="text-align: center;">
                <video widthcontrols loop autoplay muted id="crossdomain_video">
                  <source src="./files/crossdomain/scene_0008_01_000000_frame_000020.mp4" type="video/mp4"><br>
                </video>
                <h5>Freeview rendering</h5>
              </div>
            </div>
          </div>
        </center>
      </div>
    </div>

    <!-- <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <h3>
          Citation
        </h3>
        If you find our project useful, please consider citing:
        <br />

        <div class="CodeMirror cm-s-default CodeMirror-wrap">
          <div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 38.28px; left: 647px;">
            <textarea autocorrect="off" autocapitalize="off" spellcheck="false"
              style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"
              tabindex="0"></textarea>
          </div>
          <div class="CodeMirror-vscrollbar" cm-not-content="true">
            <div style="min-width: 1px; height: 0px;"></div>
          </div>
          <div class="CodeMirror-hscrollbar" cm-not-content="true">
            <div style="height: 100%; min-height: 1px; width: 0px;"></div>
          </div>
          <div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div>
          <div class="CodeMirror-gutter-filler" cm-not-content="true"></div>
          <div class="CodeMirror-scroll" tabindex="-1">
            <div class="CodeMirror-sizer"
              style="margin-left: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 111px; padding-right: 0px; padding-bottom: 0px;">
              <div style="position: relative; top: 0px;">
                <div class="CodeMirror-lines">
                  <div style="position: relative; outline: none;">
                    <div class="CodeMirror-measure">AخA</div>
                    <div class="CodeMirror-measure"></div>
                    <div style="position: relative; z-index: 1;"></div>
                    <div class="CodeMirror-cursors">
                      <div class="CodeMirror-cursor" style="left: 647px; top: 34.28px; height: 17.1406px;">&nbsp;</div>
                    </div>
                    <div class="CodeMirror-code" style="">
                      <pre
                        class=" CodeMirror-line "><span style="padding-right: 0.1px;">@inproceedings{wen2024gomavatar,</span></pre>
                      <pre
                        class=" CodeMirror-line "><span style="padding-right: 0.1px;"> &nbsp;  title={{GoMAvatar: Efficient Animatable Human Modeling from Monocular Video Using Gaussians-on-Mesh}},</span></pre>
                      <pre
                        class=" CodeMirror-line "><span style="padding-right: 0.1px;"> &nbsp;  author={Jing Wen and Xiaoming Zhao and Zhongzheng Ren and Alex Schwing and Shenlong Wang},</span></pre>
                      <pre
                        class=" CodeMirror-line "><span style="padding-right: 0.1px;"> &nbsp;  booktitle={CVPR},</span></pre>
                      <pre
                        class=" CodeMirror-line "><span style="padding-right: 0.1px;"> &nbsp;  year={2024}</span></pre>
                      <pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">}</span></pre>
                    </div>
                  </div>
                </div>
              </div>
            </div>
            <div style="position: absolute; height: 15px; width: 1px; top: 111px;"></div>
            <div class="CodeMirror-gutters" style="display: none; height: 126px;"></div>
          </div>
        </div>
      </div>
    </div> -->

    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <h3>
          Acknowledgements
        </h3>

        The website template was borrowed from <a href="http://mgharbi.com/">Michaël Gharbi</a> and <A
          href="https://climatenerf.github.io/">ClimateNeRF</a>.

      </div>
    </div>
  </div>
</body>
f

</html>
